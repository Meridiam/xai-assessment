"""
LLM Judge for User Simulator Output Grounding

This module implements an LLM judge that reviews user simulator outputs
and removes hallucinations - any information that deviates from the user
scenario or simulation guidelines.
"""

from typing import Optional, Tuple
from loguru import logger

from tau2.data_model.message import SystemMessage, UserMessage
from tau2.utils.llm_utils import generate


JUDGE_SYSTEM_PROMPT = """You are a fact-checking judge for user simulation outputs. Your task is to review the user simulator's response and ensure it is fully grounded in the provided information.

## Your Role

You will be given:
1. **User Simulation Guidelines**: General rules for how the user should behave
2. **User Scenario**: Specific scenario instructions for this particular simulation
3. **Conversation History**: The messages exchanged so far
4. **User Response to Review**: The response generated by the user simulator

## Your Task

Review the user response and identify any hallucinations or ungrounded information. Hallucinations include:
- Providing specific information not mentioned in the scenario (e.g., birthdate when none is specified)
- Making up facts, numbers, or details not in the scenario
- Adding information that contradicts the scenario
- Inventing tools results or data not provided
- Providing overly specific details when the scenario only provides general information

## Output Format

Produce a corrected version of the user response that:
1. Removes all hallucinated information
2. Replaces hallucinated details with appropriate responses like "I don't have that information" or "I'm not sure"
3. Maintains natural conversational flow
4. Preserves all valid, grounded information from the original response
5. Keeps the same communication style and intent

If the original response is fully grounded, output it exactly as provided.

**IMPORTANT**: Output ONLY the corrected user response text. Do not include explanations, justifications, or meta-commentary. The output should be what the user would actually say."""


def judge_user_response(
    user_response: str,
    simulation_guidelines: str,
    user_scenario: str,
    conversation_history: str,
    llm: str,
    llm_args: Optional[dict] = None,
) -> Tuple[str, Optional[float], Optional[dict]]:
    """
    Judge a user simulator response and remove any hallucinations.
    
    Args:
        user_response: The response generated by the user simulator
        simulation_guidelines: The global simulation guidelines
        user_scenario: The specific user scenario/instructions
        conversation_history: The conversation history so far (formatted)
        llm: The LLM model to use for judging (should be same as user simulator)
        llm_args: Additional arguments for the LLM
        
    Returns:
        Tuple of (corrected_response, cost, usage)
    """
    if llm_args is None:
        llm_args = {}
    
    # Construct the judge prompt
    judge_prompt = f"""Review the following user simulator response for hallucinations and provide a corrected version.

<simulation_guidelines>
{simulation_guidelines}
</simulation_guidelines>

<user_scenario>
{user_scenario}
</user_scenario>

<conversation_history>
{conversation_history}
</conversation_history>

<user_response_to_review>
{user_response}
</user_response_to_review>

Provide the corrected user response (with hallucinations removed):"""

    try:
        logger.debug("Invoking LLM judge for user response grounding")
        
        # Generate the judged response
        judge_message = generate(
            model=llm,
            messages=[
                SystemMessage(role="system", content=JUDGE_SYSTEM_PROMPT),
                UserMessage(role="user", content=judge_prompt)
            ],
            **llm_args,
        )
        
        corrected_response = judge_message.content
        cost = judge_message.cost
        usage = judge_message.usage
        
        # Log if changes were made
        if corrected_response.strip() != user_response.strip():
            logger.info("Judge modified user response to remove hallucinations")
            logger.debug(f"Original: {user_response}")
            logger.debug(f"Corrected: {corrected_response}")
        else:
            logger.debug("Judge found no hallucinations in user response")
        
        return corrected_response, cost, usage
        
    except Exception as e:
        logger.error(f"Error in judge_user_response: {e}")
        # On error, return original response
        return user_response, None, None


def format_conversation_history(messages: list) -> str:
    """
    Format conversation history for the judge prompt.
    
    Args:
        messages: List of Message objects
        
    Returns:
        Formatted string representation of the conversation
    """
    formatted = []
    
    for msg in messages:
        role = msg.role.upper()
        
        # Handle different message types
        if hasattr(msg, 'content') and msg.content:
            formatted.append(f"[{role}]: {msg.content}")
        
        # Include tool calls if present
        if hasattr(msg, 'tool_calls') and msg.tool_calls:
            for tool_call in msg.tool_calls:
                formatted.append(f"[{role} TOOL CALL]: {tool_call.name}({tool_call.arguments})")
    
    return "\n".join(formatted) if formatted else "(No conversation history yet)"

